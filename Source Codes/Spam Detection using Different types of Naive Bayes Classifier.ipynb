{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(r\"C:\\Users\\DIU\\Desktop\\spambase.csv\") # read the .csv file from PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>address</th>\n",
       "      <th>all</th>\n",
       "      <th>3d</th>\n",
       "      <th>our</th>\n",
       "      <th>over</th>\n",
       "      <th>remove</th>\n",
       "      <th>internet</th>\n",
       "      <th>order</th>\n",
       "      <th>mail</th>\n",
       "      <th>...</th>\n",
       "      <th>;</th>\n",
       "      <th>(</th>\n",
       "      <th>[</th>\n",
       "      <th>!</th>\n",
       "      <th>$</th>\n",
       "      <th>#</th>\n",
       "      <th>length_average</th>\n",
       "      <th>length_longest</th>\n",
       "      <th>lenth_total</th>\n",
       "      <th>spam or not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   make  address   all   3d   our  over  remove  internet  order  mail  \\\n",
       "0  0.00     0.64  0.64  0.0  0.32  0.00    0.00      0.00   0.00  0.00   \n",
       "1  0.21     0.28  0.50  0.0  0.14  0.28    0.21      0.07   0.00  0.94   \n",
       "2  0.06     0.00  0.71  0.0  1.23  0.19    0.19      0.12   0.64  0.25   \n",
       "3  0.00     0.00  0.00  0.0  0.63  0.00    0.31      0.63   0.31  0.63   \n",
       "4  0.00     0.00  0.00  0.0  0.63  0.00    0.31      0.63   0.31  0.63   \n",
       "\n",
       "      ...          ;      (    [      !      $      #  length_average  \\\n",
       "0     ...       0.00  0.000  0.0  0.778  0.000  0.000           3.756   \n",
       "1     ...       0.00  0.132  0.0  0.372  0.180  0.048           5.114   \n",
       "2     ...       0.01  0.143  0.0  0.276  0.184  0.010           9.821   \n",
       "3     ...       0.00  0.137  0.0  0.137  0.000  0.000           3.537   \n",
       "4     ...       0.00  0.135  0.0  0.135  0.000  0.000           3.537   \n",
       "\n",
       "   length_longest  lenth_total  spam or not  \n",
       "0              61          278            1  \n",
       "1             101         1028            1  \n",
       "2             485         2259            1  \n",
       "3              40          191            1  \n",
       "4              40          191            1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# according to the documentation the first 48 columns are continuous real [0,100] attributes of type word_freq_WORD \n",
    "# so we only use first 48 columns amongs all rows \n",
    "# this 48 rows are the features \n",
    "\n",
    "\n",
    "# first argument denotes rows range, and second for the columns range\n",
    "# here i select all the rows by providing nothing, and select 0 to 48 columns\n",
    "\n",
    "features = data_frame.iloc[: , 0:48] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Read the Documentation from [here](https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.DOCUMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>address</th>\n",
       "      <th>all</th>\n",
       "      <th>3d</th>\n",
       "      <th>our</th>\n",
       "      <th>over</th>\n",
       "      <th>remove</th>\n",
       "      <th>internet</th>\n",
       "      <th>order</th>\n",
       "      <th>mail</th>\n",
       "      <th>...</th>\n",
       "      <th>pm</th>\n",
       "      <th>direct</th>\n",
       "      <th>cs</th>\n",
       "      <th>meeting</th>\n",
       "      <th>original</th>\n",
       "      <th>project</th>\n",
       "      <th>re</th>\n",
       "      <th>edu</th>\n",
       "      <th>table</th>\n",
       "      <th>conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   make  address   all   3d   our  over  remove  internet  order  mail  \\\n",
       "0  0.00     0.64  0.64  0.0  0.32  0.00    0.00      0.00   0.00  0.00   \n",
       "1  0.21     0.28  0.50  0.0  0.14  0.28    0.21      0.07   0.00  0.94   \n",
       "2  0.06     0.00  0.71  0.0  1.23  0.19    0.19      0.12   0.64  0.25   \n",
       "3  0.00     0.00  0.00  0.0  0.63  0.00    0.31      0.63   0.31  0.63   \n",
       "4  0.00     0.00  0.00  0.0  0.63  0.00    0.31      0.63   0.31  0.63   \n",
       "\n",
       "      ...       pm  direct   cs  meeting  original  project    re   edu  \\\n",
       "0     ...      0.0    0.00  0.0      0.0      0.00      0.0  0.00  0.00   \n",
       "1     ...      0.0    0.00  0.0      0.0      0.00      0.0  0.00  0.00   \n",
       "2     ...      0.0    0.06  0.0      0.0      0.12      0.0  0.06  0.06   \n",
       "3     ...      0.0    0.00  0.0      0.0      0.00      0.0  0.00  0.00   \n",
       "4     ...      0.0    0.00  0.0      0.0      0.00      0.0  0.00  0.00   \n",
       "\n",
       "   table  conference  \n",
       "0    0.0         0.0  \n",
       "1    0.0         0.0  \n",
       "2    0.0         0.0  \n",
       "3    0.0         0.0  \n",
       "4    0.0         0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# according to the documentation the last columns is for the label contains whether a email spam or not\n",
    "# represent as binary format, 0 denotes 'not spam', 1 denotes 'spam'\n",
    "\n",
    "labels = data_frame.iloc[:, -1] # selecting only the last column among all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: spam or not, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4596    0\n",
       "4597    0\n",
       "4598    0\n",
       "4599    0\n",
       "4600    0\n",
       "Name: spam or not, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = .33 # means 33% test data and 67% will be train data\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = split_size, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainning data :  3082\n",
      "Percentage of training data:  66.98543794827212 %\n",
      "Number of trainning data :  1519\n",
      "Percentage of training data:  33.014562051727886 %\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of trainning data : \", len(features_train))\n",
    "\n",
    "print(\"Percentage of training data: \",len(features_train) * 100 / len(features), \"%\")\n",
    "\n",
    "print (\"Number of trainning data : \", len(labels_test))\n",
    "\n",
    "print(\"Percentage of training data: \",len(labels_test) * 100 / len(features),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in percentage :  0.8736010533245556 %\n"
     ]
    }
   ],
   "source": [
    "mlnNB = MultinomialNB()\n",
    "\n",
    "mlnNB.fit(features_train ,labels_train)\n",
    "\n",
    "pred_on_test_data = mlnNB.predict(features_test)\n",
    "\n",
    "acc_score = accuracy_score(pred_on_test_data, labels_test)\n",
    "\n",
    "print (\"Accuracy score in percentage : \" , acc_score, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quite good accuracy ! But it needs to improve\n",
    "\n",
    ">  split_size = .10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in percentage :  0.89587852494577 %\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "# firstly trying to change the split size into 10, so lets see what happens\n",
    "\n",
    "split_size = .10 # means 33% test data and 67% will be train data\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = split_size, random_state=17)\n",
    "\n",
    "mlnNB.fit(features_train ,labels_train)\n",
    "\n",
    "pred_on_test_data = mlnNB.predict(features_test)\n",
    "\n",
    "mln_pred = pred_on_test_data # 'mln_pred' will be use letter for performance measure\n",
    "\n",
    "acc_score = accuracy_score(pred_on_test_data, labels_test)\n",
    "\n",
    "print (\"Accuracy score in percentage : \" , acc_score, \"%\")\n",
    "\n",
    "print (len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great result! Lets try another classifier:\n",
    "\n",
    "## Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets try with another classifier which is Bernoulli Naive Bayes\n",
    "\n",
    "bnlNB = BernoulliNB(alpha = 1.0) # alpha '1' means smooth '0' means no smoothing\n",
    "\n",
    "bnlNB.fit(features_train, labels_train)\n",
    "\n",
    "pred_from_test_data = bnlNB.predict(features_test)\n",
    "\n",
    "bln_pred = pred_from_test_data # 'bln_pred' will be use letter for performance measure\n",
    "\n",
    "score = accuracy_score(pred_from_test_data, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in Bernoulli Classifier :  0.911062906724512 %\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy score in Bernoulli Classifier : \", score, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow ! That's Cool.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets try with another classifier which is Gaussian Naive Bayes\n",
    "\n",
    "gNB = GaussianNB() # alpha '1' means smooth '0' means no smoothing\n",
    "\n",
    "gNB.fit(features_train, labels_train)\n",
    "\n",
    "pred_from_test_data = gNB.predict(features_test)\n",
    "\n",
    "g_pred = pred_from_test_data # 'g_pred' will be use letter for performance measure\n",
    "\n",
    "score = accuracy_score(pred_from_test_data, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in Gaussian Classifier :  0.8459869848156182 %\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy score in Gaussian Classifier : \", score, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multinomial Naive Bayes Classifier Accuracy: **0.89587852494577%**\n",
    "* Bernoulli Naive Bayes Classifier Accuracy: **0.911062906724512%**\n",
    "* Gaussian Naive Bayes Classifier Accuracy: **0.8459869848156182%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfromance Testing of Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test records:  461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[193,  43],\n",
       "       [  5, 220]], dtype=int64)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now i need to test the performance of this Model\n",
    "\n",
    "# first lets check the confusion metrix \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print (\"Total test records: \", len(labels_test))\n",
    "confusion_matrix(mln_pred, labels_test, labels=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix result:\n",
    "* True Positive : **193**\n",
    "* False Positive : **43**\n",
    "* False Negative: **5**\n",
    "* True Negative : **220**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.97      0.82      0.89       236\n",
      "          0       0.84      0.98      0.90       225\n",
      "\n",
      "avg / total       0.91      0.90      0.90       461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(mln_pred, labels_test, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report:\n",
    "\n",
    "* precision : **0.91**\n",
    "* recall : **0.90**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfromance Testing of Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[172,  15],\n",
       "       [ 26, 248]], dtype=int64)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print (len(labels_test))\n",
    "\n",
    "confusion_matrix(bln_pred, labels_test, labels=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix result:\n",
    "* True Positive : **172**\n",
    "* False Positive : **15**\n",
    "* False Negative: **26**\n",
    "* True Negative : **248**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.92      0.89       187\n",
      "          0       0.94      0.91      0.92       274\n",
      "\n",
      "avg / total       0.91      0.91      0.91       461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(bln_pred, labels_test, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report:\n",
    "\n",
    "* precision : **0.91**\n",
    "* recall : **0.91**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfromance Testing of Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[195,  68],\n",
       "       [  3, 195]], dtype=int64)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print (len(labels_test))\n",
    "\n",
    "confusion_matrix(g_pred, labels_test, labels=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix result:\n",
    "* True Positive : **195**\n",
    "* False Positive : **68**\n",
    "* False Negative: **3**\n",
    "* True Negative : **195**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.98      0.74      0.85       263\n",
      "          0       0.74      0.98      0.85       198\n",
      "\n",
      "avg / total       0.88      0.85      0.85       461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(g_pred, labels_test, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report:\n",
    "\n",
    "* precision : **0.88**\n",
    "* recall : **0.85**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and performance(Confusion Matrix and Classification Report) Summary\n",
    "\n",
    "### Accuracy:\n",
    "\n",
    "* Multinomial Naive Bayes Classifier Accuracy: **0.89587852494577%**\n",
    "* Bernoulli Naive Bayes Classifier Accuracy: **0.911062906724512%**\n",
    "* Gaussian Naive Bayes Classifier Accuracy: **0.8459869848156182%**\n",
    "\n",
    "### Performance:\n",
    "##### Multinomial Naive Bayes\n",
    "* Total truthy result : **413**\n",
    "* Total falsy result : **48** \n",
    "\n",
    "##### Burnoulli Naive Bayes\n",
    "* Total truthy result : **420**\n",
    "* Total falsy result : **41**\n",
    "\n",
    "##### Gaussian Naive Bayes\n",
    "* Total truthy result : **390**\n",
    "* Total falsy result : **71**\n",
    "\n",
    "\n",
    "### Classification Report:\n",
    "##### Multinomial Naive Bayes\n",
    "* precision : **0.91**\n",
    "* recall : **0.90**\n",
    "\n",
    "##### Burnoulli Naive Bayes\n",
    "* precision : **0.91**\n",
    "* recall : **0.91**\n",
    "\n",
    "##### Gaussian Naive Bayes\n",
    "* precision : **0.88**\n",
    "* recall : **0.85**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### So according to the result summary i can conclude that Burnoulli Naive Bayes Classifier will gives the optimal and best result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
